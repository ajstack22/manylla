# Atlas Performance Evidence Template v2.0
# This YAML template provides a standardized format for capturing performance evidence

evidence_metadata:
  id: "EVD-{YYYYMMDD}-{HHmm}-performance-{sequence}"
  type: "performance"
  version: "2.0"
  phase: "review"  # Can be implementation or review
  story_id: ""  # e.g., "S001"
  sprint_id: ""  # e.g., "SP-2024-10"
  created_at: ""  # ISO 8601 format
  created_by: ""  # automated|tester_name
  tools_used: []  # e.g., ["jmeter", "gatling", "k6", "artillery"]
  environment: ""  # dev|staging|production|synthetic
  validation_status: "pending"  # pending|validated|rejected
  retention_policy: "6months"

test_configuration:
  test_run_id: ""  # e.g., "PERF-20241115-1045-load"
  test_type: ""  # load|stress|volume|endurance|spike|scalability
  test_objective: ""  # Brief description of test purpose
  test_duration: ""  # HH:MM:SS
  ramp_up_time: ""  # HH:MM:SS
  ramp_down_time: ""  # HH:MM:SS
  steady_state_time: ""  # HH:MM:SS
  test_tool: ""  # jmeter|gatling|k6|artillery|custom
  test_script_version: ""
  test_data_version: ""

test_environment:
  environment_name: ""  # e.g., "staging", "production-like"
  environment_url: ""
  application_version: ""
  database_version: ""
  infrastructure_type: ""  # cloud|on_premise|hybrid

  system_under_test:
    application_servers:
      - name: ""  # e.g., "app-server-01"
        cpu_cores: 0
        memory_gb: 0
        os: ""
        jvm_version: ""  # If applicable
        instance_type: ""  # e.g., "t3.large"

    database_servers:
      - name: ""
        cpu_cores: 0
        memory_gb: 0
        storage_type: ""  # SSD|HDD
        storage_size_gb: 0
        connection_pool_size: 0

    load_balancers:
      - name: ""
        type: ""  # application|network
        algorithm: ""  # round_robin|least_connections
        health_check_interval: ""

    caching_layer:
      - name: ""
        type: ""  # redis|memcached|application
        memory_allocated: ""
        hit_ratio_target: 0.0

  network_configuration:
    bandwidth: ""  # e.g., "1Gbps"
    latency: ""  # e.g., "10ms"
    packet_loss: 0.0  # Percentage
    cdn_enabled: false

load_profile:
  concurrent_users: 0
  user_ramp_rate: ""  # e.g., "10 users/minute"
  think_time: ""  # e.g., "2-5 seconds"
  session_duration: ""  # Average user session length

  test_scenarios:
    - name: ""  # e.g., "user_login"
      description: ""
      weight: 0.0  # Percentage of total load
      transactions: 0
      data_variation: ""  # static|dynamic|parameterized

    - name: ""  # e.g., "browse_products"
      description: ""
      weight: 0.0
      transactions: 0
      data_variation: ""

  user_behavior_model:
    new_users_percentage: 0.0
    returning_users_percentage: 0.0
    premium_users_percentage: 0.0
    mobile_users_percentage: 0.0

response_time_metrics:
  overall:
    samples: 0
    average: ""  # e.g., "145ms"
    median: ""  # e.g., "120ms"
    p50: ""  # 50th percentile
    p90: ""  # 90th percentile
    p95: ""  # 95th percentile
    p99: ""  # 99th percentile
    p99_9: ""  # 99.9th percentile
    min: ""  # e.g., "45ms"
    max: ""  # e.g., "2.1s"
    standard_deviation: ""

  by_transaction:
    - transaction: ""  # e.g., "/api/auth/login"
      samples: 0
      average: ""
      median: ""
      p95: ""
      p99: ""
      sla_target: ""  # e.g., "< 200ms"
      sla_compliance: 0.0  # Percentage
      errors: 0

    - transaction: ""  # e.g., "/api/products/search"
      samples: 0
      average: ""
      median: ""
      p95: ""
      p99: ""
      sla_target: ""
      sla_compliance: 0.0
      errors: 0

  time_series_data:
    interval: ""  # e.g., "30s"
    data_points:
      - timestamp: ""  # ISO 8601
        average_response_time: ""
        concurrent_users: 0
        throughput: 0.0
        error_rate: 0.0

throughput_metrics:
  requests_per_second: 0.0
  transactions_per_second: 0.0
  transactions_per_minute: 0.0
  data_transferred_per_second: ""  # e.g., "2.5MB/s"

  successful_requests:
    count: 0
    percentage: 0.0

  failed_requests:
    count: 0
    percentage: 0.0

  error_analysis:
    timeout_errors: 0
    connection_errors: 0
    http_4xx_errors: 0
    http_5xx_errors: 0
    application_errors: 0

    error_details:
      - error_type: ""  # e.g., "timeout", "502_bad_gateway"
        count: 0
        percentage: 0.0
        first_occurrence: ""  # ISO 8601
        peak_occurrence_time: ""
        sample_message: ""

resource_utilization:
  application_servers:
    - server: ""  # e.g., "app-01"
      monitoring_tool: ""  # e.g., "prometheus", "newrelic"

      cpu:
        average: 0.0  # Percentage
        peak: 0.0
        user_space: 0.0
        system_space: 0.0
        idle: 0.0
        iowait: 0.0

      memory:
        total_gb: 0.0
        used_gb: 0.0
        available_gb: 0.0
        utilization_percentage: 0.0
        swap_used: 0.0

      disk:
        read_iops: 0.0
        write_iops: 0.0
        read_throughput: ""  # e.g., "50MB/s"
        write_throughput: ""
        utilization_percentage: 0.0
        queue_depth: 0.0

      network:
        incoming_mbps: 0.0
        outgoing_mbps: 0.0
        packets_per_second: 0.0
        dropped_packets: 0
        retransmissions: 0

      application_metrics:
        active_threads: 0
        thread_pool_utilization: 0.0
        heap_memory_used: ""  # e.g., "1.2GB"
        heap_memory_max: ""
        gc_frequency: 0.0  # Collections per minute
        gc_pause_time: ""  # Average GC pause

  database_servers:
    - server: ""  # e.g., "db-primary"

      cpu:
        average: 0.0
        peak: 0.0

      memory:
        total_gb: 0.0
        used_gb: 0.0
        buffer_pool_hit_ratio: 0.0

      storage:
        read_iops: 0.0
        write_iops: 0.0
        read_latency: ""  # e.g., "2ms"
        write_latency: ""

      database_metrics:
        active_connections: 0
        max_connections: 0
        connection_pool_utilization: 0.0
        slow_queries: 0
        deadlocks: 0
        cache_hit_ratio: 0.0
        replication_lag: ""  # For replica servers

  infrastructure:
    load_balancer:
      cpu_utilization: 0.0
      memory_utilization: 0.0
      active_connections: 0
      requests_per_second: 0.0

    caching_layer:
      - cache_name: ""
        hit_ratio: 0.0
        miss_ratio: 0.0
        eviction_rate: 0.0
        memory_utilization: 0.0
        operations_per_second: 0.0

scalability_analysis:
  linear_scalability_range:
    from_users: 0
    to_users: 0
    throughput_increase: 0.0  # Percentage

  performance_degradation:
    degradation_start_users: 0
    degradation_percentage: 0.0
    response_time_increase: 0.0

  system_limits:
    max_sustainable_users: 0
    breaking_point_users: 0
    failure_mode: ""  # e.g., "database_connections", "memory_exhaustion"

  bottleneck_identification:
    - component: ""  # e.g., "database_connection_pool"
      utilization_at_limit: 0.0
      impact: ""  # high|medium|low
      recommendation: ""

    - component: ""  # e.g., "cpu_processing"
      utilization_at_limit: 0.0
      impact: ""
      recommendation: ""

memory_analysis:
  application_memory:
    initial_allocation: ""  # e.g., "512MB"
    peak_usage: ""  # e.g., "1.2GB"
    average_usage: ""
    memory_growth_rate: ""  # Per hour

  garbage_collection:
    gc_algorithm: ""  # e.g., "G1GC", "CMS"
    total_collections: 0
    total_gc_time: ""  # Total time spent in GC
    average_gc_time: ""
    max_gc_time: ""
    gc_overhead: 0.0  # Percentage of total time

  memory_leaks:
    leak_detected: false
    leak_rate: ""  # If detected, e.g., "5MB/hour"
    suspected_components: []

  off_heap_memory:
    direct_memory_used: ""
    mapped_memory_used: ""
    cache_memory_used: ""

network_analysis:
  bandwidth_utilization:
    incoming: 0.0  # Percentage of available bandwidth
    outgoing: 0.0

  latency_breakdown:
    client_to_load_balancer: ""  # e.g., "12ms"
    load_balancer_to_app: ""  # e.g., "2ms"
    app_to_database: ""  # e.g., "8ms"
    app_to_external_service: ""  # e.g., "45ms"

  connection_analysis:
    concurrent_connections: 0
    new_connections_per_second: 0.0
    connection_reuse_ratio: 0.0
    connection_timeouts: 0

  packet_analysis:
    packets_sent: 0
    packets_received: 0
    packet_loss: 0.0  # Percentage
    retransmissions: 0
    out_of_order_packets: 0

caching_performance:
  application_cache:
    - cache_name: ""  # e.g., "user_sessions"
      hit_ratio: 0.0
      miss_ratio: 0.0
      size_mb: 0.0
      eviction_count: 0
      eviction_policy: ""  # LRU|LFU|FIFO

  database_cache:
    query_cache_hit_ratio: 0.0
    buffer_pool_hit_ratio: 0.0
    index_cache_hit_ratio: 0.0

  external_cache:
    - cache_type: ""  # redis|memcached
      hit_ratio: 0.0
      response_time: ""
      throughput: ""  # operations per second
      memory_usage: ""

baseline_comparison:
  comparison_baseline:
    baseline_version: ""  # e.g., "v2.0.7"
    baseline_date: ""  # ISO 8601
    baseline_environment: ""

  performance_delta:
    response_time_change: ""  # e.g., "+5% (slower)", "-3% (faster)"
    throughput_change: ""
    resource_usage_change: ""
    error_rate_change: ""

  regression_analysis:
    significant_regressions: []  # List of metrics with >10% degradation
    performance_improvements: []  # List of metrics with >10% improvement
    overall_assessment: ""  # improved|degraded|stable

  trend_analysis:
    velocity_trend: ""  # improving|declining|stable
    quality_vs_performance: ""  # Analysis of trade-offs

sla_compliance:
  defined_slas:
    - metric: ""  # e.g., "response_time_95th"
      target: ""  # e.g., "< 500ms"
      actual: ""
      compliance_percentage: 0.0
      status: ""  # met|exceeded|violated

    - metric: ""  # e.g., "availability"
      target: ""  # e.g., "99.9%"
      actual: ""
      compliance_percentage: 0.0
      status: ""

  availability_metrics:
    uptime_percentage: 0.0
    downtime_duration: ""  # Total downtime during test
    mtbf: ""  # Mean Time Between Failures
    mttr: ""  # Mean Time To Recovery

stress_test_results:
  stress_test_executed: false

  # Only include if stress test was performed
  breaking_point:
    concurrent_users: 0
    failure_symptoms: []  # e.g., ["connection_timeouts", "memory_exhaustion"]
    recovery_time: ""  # Time to return to normal after stress

  graceful_degradation:
    degradation_observed: false
    degradation_pattern: ""  # gradual|sudden|stepped
    critical_functions_maintained: []

endurance_test_results:
  endurance_test_executed: false

  # Only include if endurance test was performed
  test_duration: ""  # e.g., "08:00:00"

  performance_stability:
    initial_response_time: ""
    final_response_time: ""
    performance_drift: 0.0  # Percentage change

  resource_trends:
    memory_growth: ""  # Linear|exponential|stable
    cpu_trend: ""
    disk_usage_growth: ""

  long_term_issues:
    memory_leaks_detected: false
    connection_leaks_detected: false
    file_handle_leaks_detected: false
    performance_anomalies: []

recommendations:
  immediate_actions:
    - priority: ""  # critical|high|medium|low
      action: ""
      component: ""
      estimated_effort: ""
      expected_improvement: ""

  short_term_improvements:
    - priority: ""
      action: ""
      component: ""
      estimated_effort: ""
      expected_improvement: ""

  long_term_optimizations:
    - priority: ""
      action: ""
      component: ""
      estimated_effort: ""
      expected_improvement: ""

  capacity_planning:
    current_capacity: ""  # Current max sustainable load
    projected_growth: ""  # Expected load increase
    scaling_recommendations: []
    infrastructure_changes: []

evidence_files:
  - name: "performance-test-plan.pdf"
    path: ""
    size: ""
    checksum: ""
    description: "Detailed performance test plan and scenarios"

  - name: "jmeter-results.jtl"
    path: ""
    size: ""
    checksum: ""
    description: "Raw JMeter test results"

  - name: "system-monitoring-dashboard.png"
    path: ""
    size: ""
    checksum: ""
    description: "System monitoring screenshots during test"

  - name: "performance-report.html"
    path: ""
    size: ""
    checksum: ""
    description: "Comprehensive performance analysis report"

  - name: "resource-utilization-graphs.pdf"
    path: ""
    size: ""
    checksum: ""
    description: "Resource utilization trends and analysis"

validation_rules:
  critical:
    - response_time_95th <= sla_target
    - error_rate < 1.0  # Percentage
    - availability >= 99.9

  blocking:
    - performance_regression < 20.0  # Percentage
    - resource_utilization < 90.0
    - scalability_target_met == true

  warning:
    - response_time_average <= baseline * 1.1
    - throughput >= baseline * 0.9
    - memory_usage < 85.0

quality_gates:
  performance_requirements:
    max_response_time_95th: ""  # e.g., "500ms"
    min_throughput: ""  # e.g., "100 req/sec"
    max_error_rate: 1.0  # Percentage
    min_availability: 99.9  # Percentage

  resource_constraints:
    max_cpu_utilization: 80.0  # Percentage
    max_memory_utilization: 85.0
    max_disk_utilization: 80.0

  scalability_requirements:
    min_concurrent_users: 0
    linear_scalability_range: 0  # Number of users
    max_performance_degradation: 10.0  # Percentage

# Usage Instructions:
# 1. Configure test parameters based on your performance requirements
# 2. Fill in actual measurement data from your performance tests
# 3. Include baseline comparisons for trend analysis
# 4. Document any performance regressions or improvements
# 5. Provide actionable recommendations based on findings
# 6. Ensure all evidence files are properly archived and accessible